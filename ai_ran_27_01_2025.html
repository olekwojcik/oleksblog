<html>
  <div class="topnav">
  <a class="active" href="/">Home</a>
</div>
 <html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_iz9litcgoexv-0>li:before{content:"-  "}.lst-kix_iz9litcgoexv-8>li:before{content:"-  "}.lst-kix_iz9litcgoexv-7>li:before{content:"-  "}.lst-kix_iz9litcgoexv-6>li:before{content:"-  "}.lst-kix_iz9litcgoexv-4>li:before{content:"-  "}ul.lst-kix_iz9litcgoexv-5{list-style-type:none}ul.lst-kix_iz9litcgoexv-4{list-style-type:none}.lst-kix_iz9litcgoexv-3>li:before{content:"-  "}ul.lst-kix_iz9litcgoexv-3{list-style-type:none}.lst-kix_iz9litcgoexv-5>li:before{content:"-  "}ul.lst-kix_iz9litcgoexv-2{list-style-type:none}ul.lst-kix_iz9litcgoexv-8{list-style-type:none}ul.lst-kix_iz9litcgoexv-7{list-style-type:none}ul.lst-kix_iz9litcgoexv-6{list-style-type:none}.lst-kix_iz9litcgoexv-1>li:before{content:"-  "}ul.lst-kix_iz9litcgoexv-1{list-style-type:none}.lst-kix_iz9litcgoexv-2>li:before{content:"-  "}ul.lst-kix_iz9litcgoexv-0{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left;height:11pt}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Times New Roman";font-style:normal}.c3{padding-top:0pt;padding-bottom:0pt;line-height:1.0;orphans:2;widows:2;text-align:left}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Times New Roman";font-style:normal}.c8{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-family:"Times New Roman"}.c10{text-decoration-skip-ink:none;-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline}.c7{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c4{color:inherit;text-decoration:inherit}.c1{font-size:13pt;font-style:italic}.c11{font-weight:700}.c2{font-size:13pt}.c9{text-indent:36pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Times New Roman"}p{margin:0;color:#000000;font-size:11pt;font-family:"Times New Roman"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Times New Roman";line-height:1.0;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c7 doc-content"><p class="c3"><span class="c2 c11">Stop Saying LLMs are AI!</span></p><p class="c0"><span class="c6 c2"></span></p><p class="c3"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;I love depictions of Artificial Intelligence in fiction. From </span><span class="c1">Star Trek</span><span class="c2">&nbsp;to </span><span class="c1">Mass Effect</span><span class="c2">, from </span><span class="c1">Bajki Robot&oacute;w</span><span class="c2">&nbsp;to </span><span class="c1">Space Odyssey</span><span class="c6 c2">, AI allows science fiction writers to ask endless questions about the nature of ourselves and our world. What does it mean to be human? What would a post-scarcity world look like? Is it right to exploit an artificial mind for labor? Is creating a being more intelligent than us dangerous? I am always delighted with the myriad of ways that sci-fi stories about AI allow for genuine reflection on ideas I would not have otherwise considered. &nbsp;</span></p><p class="c0"><span class="c6 c2"></span></p><p class="c3"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;This is why I implore you: </span><span class="c1">stop referring to LLMs as AI</span><span class="c6 c2">.</span></p><p class="c0"><span class="c6 c2"></span></p><p class="c3 c9"><span class="c6 c2">I have decided to take a stand. The decision to call Large Language Models AI is nothing more than a massively successful marketing strategy that hijacks our preconceptions to convince us that LLMs are the mythical AI we know from sci-fi media. But LLMs and sci-fi AI are separate concepts that have absolutely nothing to do with one another.</span></p><p class="c0"><span class="c6 c2"></span></p><p class="c3 c9"><span class="c2">LLMs have undoubtedly had a massive impact on life in the 2020s, from enabling software engineers to automate monotonous tasks to helping high school students cheat on their homework. They are best thought of as </span><span class="c1">predictive algorithms</span><span class="c6 c2">&mdash;they are not &ldquo;thinking&rdquo; in the traditional sense. When you ask them something like: &ldquo;How do I cook rice?&rdquo; the LLM takes a look at its training data, takes the average of every answer to the question &ldquo;How do I cook rice?&rdquo; it can find, adheres to some prompts made by engineers to make it seem like it&rsquo;s talking to you, throws in some randomness to keep its answer from being too dry, and gives you text that looks like it could be an original thought from a conscious being. </span></p><p class="c3 c9"><span class="c2">Why does this mean that LLMs don&rsquo;t &ldquo;think&rdquo; like us? If, after all, an AI passes the Turing Test and becomes indistinguishable from an actual intelligence, is that not enough to count it as an actual intelligence comparable to our own? In this case, no. This becomes apparent when </span><span class="c2 c10"><a class="c4" href="https://www.google.com/url?q=https://arxiv.org/abs/2301.13867?utm_source%3Dchatgpt.com&amp;sa=D&amp;source=editors&amp;ust=1738012486205781&amp;usg=AOvVaw1Jug80n7LOSnhAJHmiDt3Q">LLMs attempt to do advanced mathematics</a></span><span class="c6 c2">. When asked a relatively straightforward math question, ChatGPT fairs very well. As before, it looks into its training data, finds the various times that question was asked, and averages out the answers to give you a reasonable output. When it comes to graduate-level mathematical questions, ChatGPT&rsquo;s data is limited. It can&rsquo;t answer the question accurately because few people in its training data have answered it or any similar ones. This is why LLMs aren&rsquo;t &ldquo;intelligent&rdquo; in the same way we are. A human being works through the mathematical problem itself by reasoning it out, while an LLM just finds what the most likely answer to a mathematical problem is based on other similar answers to similar mathematical problems. LLMs are demonstrably incapable of reasoning beyond the scope of their training data, and there is no reason to believe that is changing.</span></p><p class="c3 c9"><span class="c2">The definition of &ldquo;AI&rdquo; is kept intentionally imprecise as well, in order to make it broad enough to include LLMs, which would not be considered intelligent under any restrictive definition. The colloquial definitions which Sam Altman often alludes to are than an AI 1. models human thought and 2. is capable of learning, adaption and prediction. That sounds perfectly reasonable, but this is so broad that it includes a</span><span class="c1">&nbsp;mean</span><span class="c6 c2">. A mean is an algorithm that models human thought, is capable of learning, it adapts to new data, and it is often used for prediction. LLMs, like summary statistics, are useful in many cases but will not spontaneously blossom into general intelligences.</span></p><p class="c0"><span class="c8 c1"></span></p><p class="c0 c9"><span class="c6 c2"></span></p><p class="c3"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In March of 2023, an </span><span class="c10 c2"><a class="c4" href="https://www.google.com/url?q=https://futureoflife.org/open-letter/pause-giant-ai-experiments/&amp;sa=D&amp;source=editors&amp;ust=1738012486206470&amp;usg=AOvVaw2zbUi_Wt2k5KY5RWf8DllZ">open letter </a></span><span class="c6 c2">was signed by a host of illustrious tech figures such as Elon Musk and Steve Wozniak calling for a six-month pause on AI research due to &ldquo;profound risks to society and humanity&rdquo; from &ldquo;AI systems&hellip; human-competitive at general tasks.&rdquo; It warned that these AI systems have the potential to replace humanity and cause us to lose control of our own civilization. The letter was widely reported on and fueled the ongoing debate regarding the societal implications of Artificial General Intelligence, or AGI, which is typically defined as an AI that is capable of completing any cognitive task that a human being can perform. Should we allow the continued unrestricted research into such a dangerous and unpredictable technology? It has been about two years since the publication of that letter, and the sixth-month pause it called for was never implemented. Surprisingly, as I write this, our civilization has yet to be obliterated by a rogue AI. Maybe next year?</span></p><p class="c3"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sam Altman has been talking about &ldquo;AGI&rdquo; for years now, and he describes AGI himself as the AI &ldquo;from science fiction movies&rdquo;. When users of ChatGPT correctly notice that it behaves nothing like an AI from movies, the promise of AGI serves as padding between expectations and reality. Of course, ChatGPT is</span><span class="c2">&nbsp;</span><span class="c1">AI</span><span class="c2">, but it is not yet </span><span class="c1">AGI</span><span class="c6 c2">, which is coming very soon and will fulfill all your wildest sci-fi movie dreams.</span></p><p class="c3"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;What is interesting about that letter is that the major source of the signatories&rsquo; concerns was OpenAI and its own grandiose speculations about itself. Why would OpenAI and Sam Altman push for the idea that the technology they are working on is potentially apocalyptic? Because, if the debate is over the dangers of AGI, the implication within that debate is that AGI will inevitably be created. In his writings and interviews, Altman constantly and conspicuously mentions that he does not fear AGI &ldquo;replacing&rdquo; us, or that we have &ldquo;nothing to fear&rdquo; from AI as long as it is used &ldquo;responsibly&rdquo;. OpenAI&rsquo;s </span><span class="c10 c2"><a class="c4" href="https://www.google.com/url?q=https://openai.com/index/planning-for-agi-and-beyond/&amp;sa=D&amp;source=editors&amp;ust=1738012486207343&amp;usg=AOvVaw3LeQg4ftO3jjdnjFIch17R">blog post</a></span><span class="c2">&nbsp;on planning for AGI includes all sorts of references to &ldquo;massive risks&rdquo; and &ldquo;grievous harm&rdquo; alongside the vague promises of &ldquo;elevating humanity&rdquo; and &ldquo;abundance&rdquo;. Altman intentionally sets up a rhetorical trap this way; by preemptively providing a strawman AI doomer counterargument, any detractors sound like technophobic Luddites rather than common-sense skeptics. This strategy has been incredibly effective in shifting the conversation to the </span><span class="c1">consequences</span><span class="c2">&nbsp;of AI and away from its </span><span class="c1">existence</span><span class="c2 c6">. </span></p><p class="c3"><span class="c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Altman speaks of AI as the frontier of a new revolution, comparable to the agricultural and industrial revolutions. He says AI has &ldquo;no upper bound&rdquo; and that its growth is &ldquo;exponential&rdquo;. That all sounds fantastic, and even believable, but there is one issue: </span><span class="c1">LLMs are not sci-fi AI. </span><span class="c2">There is no reason to believe that LLMs do not have an upper bound, and indeed it seems like we began to skirt against that upper bound a while ago. While some users may claim that ChatGPT has improved incrementally, it is undeniable to any regular user that&mdash;as a product&mdash;it has mostly remained roughly comparable in its capabilities to what it was a year ago. If the technology developed exponentially, and with no upper bound, then by definition it should be improving faster and faster. Instead, it is plateauing&mdash;both anecdotally, and according to </span><span class="c10 c2"><a class="c4" href="https://www.google.com/url?q=https://arxiv.org/pdf/2307.09009&amp;sa=D&amp;source=editors&amp;ust=1738012486208112&amp;usg=AOvVaw03pjimswmph0aoRUZN3ktU">studies</a></span><span class="c2">&nbsp;that have attempted to measure its cognitive abilities over time. In order to assure us that AI is still advancing, OpenAI has focused on </span><span class="c1">horizontal </span><span class="c2">development of AI rather than </span><span class="c1">vertical</span><span class="c2">. They publish models which have nothing to do with ChatGPT, which output image and video content, or a browser bot, and they label these as &ldquo;AI&rdquo; to fool investors and fans into thinking that it is &nbsp;same core technology being advanced as the one behind ChatGPT. But it isn&rsquo;t. It is a way to distract from the fact that their LLM, which was supposed to be limitless in its potential, has hit its upper bound.</span></p><p class="c0"><span class="c6 c2"></span></p><p class="c3"><span class="c6 c2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&ldquo;AI&rdquo; is a bubble. Sam Altman is a magician who pulls a rabbit out of a hat, and insists that the trick was done with actual magic rather than a secret compartment in his hat. The magic here is AI, and the magic trick is LLMs. There is nothing to be ashamed about when it comes to magic tricks&mdash;especially good ones&mdash;since they take true creativity and skill. But when we start worshipping magicians as gods or burning them as witches, we ought to take a step back and consider our actions. LLMs are neat predictive statistical models that can serve many purposes, but they are not magic, and they are not AI. AGI is not coming anytime soon, and there is no reason to believe it will come from LLMs. The sooner we realize that, and the sooner we pop this bubble, the better. Until then, I will bristle every time someone refers to an LLM as Artificial Intelligence.</span></p><p class="c0"><span class="c5"></span></p></body></html>
